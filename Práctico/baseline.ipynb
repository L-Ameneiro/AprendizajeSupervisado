{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DiploDatos Kaggle Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presentamos un código creado como ejemplo de base para la competición.\n",
    "\n",
    "Deben:\n",
    "\n",
    "- Explorar los datos y aprender de ellos.\n",
    "- Probar diferentes modelos y ver cuáles ajustan mejor dado los datos.\n",
    "- Para esta competencia se elige como métrica el **recall_score**. Discutir, analizar y justificar porque es necesaria está métrica para este problema. \n",
    "- **Obtener una recall mejor que la que se presenta en este ejemplo.**\n",
    "- Tratar de obtener un score lo más alto posible!\n",
    "- Discutir la elección de modelo.\n",
    "\n",
    "El análisis exploratorio y el preprocesamiento de los datos queda a libertad de cada grupo y no deben quedarse con este simple ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import recall_score, ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leer el dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos de entrenamiento que vamos a utilizar para generar nuestro modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('diabetes_prediction_dataset_train-labeled.csv')\n",
    "print(train_df.shape)\n",
    "print(train_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La columna ***`diabetes`*** es la columna que debemos predecir. En el dataset de Test esta columna tiene valores nulos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos de test. Estos datos son los que van a utilizar para predecir si las personas tienen diabetes y generar alrchivo `submision.csv` para utilizar en la competencia de Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('diabetes_prediction_dataset_test.csv')\n",
    "print(test_df.shape)\n",
    "print(test_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisis de los datos \n",
    "\n",
    "veamos si hay desbalances.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.groupby(\"patient\").diabetes.mean().value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¡Clases desbalanceadas!** y que sucede si analizamos genero y edad?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necesitamos contruir nuestros conjuntos de datos para realizar los entrenamientos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer_cols = [\"patient\", \"age\", \"hypertension\", \"heart_disease\", \"bmi\" ,\"HbA1c_level\", \"blood_glucose_level\", \"diabetes\"]\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "train_df[imputer_cols] = imputer.fit_transform(train_df[imputer_cols])\n",
    "y = train_df.diabetes\n",
    "X = train_df.drop('diabetes',axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a separar la columna con los Id de los pacientes en una sola variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patientId = X.patient\n",
    "X.drop('patient',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necesitamos transformar las variables que son categoricas a númericas, como por ejemplo **gender** y **smoking_history**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.columns)\n",
    "label_cols = [\"gender\", \"smoking_history\"]\n",
    "\n",
    "for col in label_cols:\n",
    "    X[col] = X[col].astype(str)\n",
    "    X[col] = LabelEncoder().fit_transform(X[col])\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necesitamos también estandarizar las variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_names = X.columns\n",
    "X = StandardScaler().fit_transform(X)\n",
    "X = pd.DataFrame(X, columns=x_names)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de los datos en las variables `X` e `y` separamos en train y en test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Planteo de modelos\n",
    "Tienen que elegir los 2 mejores modelos así que prueben con varios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = [DecisionTreeClassifier()]\n",
    "names = ['Árbol de decisión']\n",
    "\n",
    "trained_models = []\n",
    "accuracy_models = []\n",
    "for clf,name in zip(clfs,names):\n",
    "    print(name)\n",
    "    clf.fit(x_train, y_train)\n",
    "    train_predictions = clf.predict(x_train)\n",
    "    recall = recall_score(y_train, train_predictions)\n",
    "    print(f\"Recall train {name}: %.2f%%\" % (recall * 100.0))\n",
    "\n",
    "    train_predictions = clf.predict(x_test)\n",
    "    recall = recall_score(y_test, train_predictions)\n",
    "    print(\"Recall test {name}: %.2f%%\" % (recall * 100.0))\n",
    "    # plot_confusion_matrix(clf,x_test,y_test)\n",
    "    trained_models.append(clf)\n",
    "    accuracy_models.append(recall*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algún tipo de ajuste de hiperparámetros de los modelos elegidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(DecisionTreeClassifier(),\n",
    " {'criterion':('gini','entropy'),\n",
    " 'splitter':(\"best\",\"random\"),\n",
    "  'min_samples_leaf':(1, 2, 5),\n",
    "  'min_samples_split':(2, 3, 5, 10, 50, 100),\n",
    " 'max_depth':(5,10,20)})\n",
    "grid.fit(x_train,y_train)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(**grid.best_params_).fit(x_train, y_train)\n",
    "\n",
    "train_predictions = clf.predict(x_train)\n",
    "recall = recall_score(y_train, train_predictions)\n",
    "print(\"Recall train Arbol de decisión: %.2f%%\" % (recall * 100.0))\n",
    "\n",
    "test_predictions = clf.predict(x_test)\n",
    "recall = recall_score(y_test, test_predictions)\n",
    "print(\"Recall test Arbol de decisión: %.2f%%\" % (recall * 100.0))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, test_predictions)\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_test,clf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDS=5\n",
    "cv = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=10)\n",
    "\n",
    "x_train2 = np.array(x_train)\n",
    "y_train2 = np.array(y_train)\n",
    "\n",
    "\n",
    "for clfi, name in zip([DecisionTreeClassifier(**grid.best_params_)],names):\n",
    "    print(clfi)\n",
    "    avg_recall = 0\n",
    "    for fold, (train_idx, val_idx) in enumerate(cv.split(x_train2, y_train2)):\n",
    "        xi, yi = x_train2[train_idx], y_train2[train_idx]\n",
    "        x_valid, y_valid = x_train2[val_idx], y_train2[val_idx]\n",
    "        clfi = clfi.fit(xi, yi)\n",
    "\n",
    "        test_predictions = clfi.predict(x_valid)\n",
    "        recall = recall_score(y_valid, test_predictions)\n",
    "        avg_recall +=recall\n",
    "        print(f\"Recall test fold {fold}: {recall * 100.0 :.2f}\" % ())\n",
    "\n",
    "    avg_recall /= FOLDS\n",
    "    print(f'Avg. recall = {avg_recall * 100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generar la salida para entregar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('diabetes_prediction_dataset_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder evaluar nuestra predicción los datos de prueba deben tener exactamente el mismo tratamiento que los datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = test_df.diabetes\n",
    "PatientId_test = test_df['patient']\n",
    "X_test = test_df.drop(['patient','diabetes'],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer_cols = [\"age\", \"hypertension\", \"heart_disease\", \"bmi\" ,\"HbA1c_level\", \"blood_glucose_level\"]\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "X_test[imputer_cols] = imputer.fit_transform(X_test[imputer_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = [\"gender\", \"smoking_history\"]\n",
    "\n",
    "for col in label_cols:\n",
    "    X_test[col] = X_test[col].astype(str)\n",
    "    X_test[col] = LabelEncoder().fit_transform(X_test[col])\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = X_test.columns\n",
    "X_test = StandardScaler().fit_transform(X_test)\n",
    "X_test = pd.DataFrame(X_test, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos la salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = PatientId_test\n",
    "test_pred = np.int64(clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el resultado predicho tenemos que generar el archivo `.csv` para subir a la competencia de kaggle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(list(zip(test_id, test_pred)), columns=[\"patient\", \"diabetes\"])\n",
    "submission.to_csv(\"sample_submission.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Suerte!! :D**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "e6b65fc4380ac725e50a330b268a227bbdbe91bddfffbf68e5f7ce9848a2b8d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
